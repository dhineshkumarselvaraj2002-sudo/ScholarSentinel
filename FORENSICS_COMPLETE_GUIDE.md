# Diagram Forensics Engine - Complete Implementation Guide

## ğŸ¯ System Overview

The **Diagram Forensics Engine** is a complete, locally-running AI-powered system for detecting diagram plagiarism in PDF documents. It combines multiple detection techniques:

1. **Perceptual Hashing** - Detects exact and near-exact duplicates
2. **OpenCV Feature Matching** - Detects edited/cropped versions
3. **Reverse Image Search** - Finds similar images on the web
4. **Local Comparison** - Compares against reference database

**Key Features:**
- âœ… 100% Local Processing (No Cloud APIs)
- âœ… Background Job Queue (BullMQ + Redis)
- âœ… Comprehensive Reporting
- âœ… Real-time Progress Tracking
- âœ… Modern Web UI

## ğŸ“ Complete File Structure

```
ScholarSentinel/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ extract/
â”‚   â”‚   â”‚   â””â”€â”€ route.ts                    # Module A API
â”‚   â”‚   â”œâ”€â”€ hashing/
â”‚   â”‚   â”‚   â””â”€â”€ route.ts                    # Module B API
â”‚   â”‚   â”œâ”€â”€ compare/
â”‚   â”‚   â”‚   â””â”€â”€ route.ts                    # Module C API
â”‚   â”‚   â”œâ”€â”€ reverse/
â”‚   â”‚   â”‚   â””â”€â”€ route.ts                    # Module D API
â”‚   â”‚   â””â”€â”€ forensics/
â”‚   â”‚       â”œâ”€â”€ scan/
â”‚   â”‚       â”‚   â””â”€â”€ route.ts                # Start scan
â”‚   â”‚       â”œâ”€â”€ status/
â”‚   â”‚       â”‚   â””â”€â”€ route.ts                 # Job status
â”‚   â”‚       â””â”€â”€ report/
â”‚   â”‚           â””â”€â”€ route.ts                 # Get report
â”‚   â””â”€â”€ forensics/
â”‚       â””â”€â”€ page.tsx                         # Module G: Frontend UI
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ pdf_extractor.py                     # Module A: PDF extraction
â”‚   â”œâ”€â”€ image_hashing.py                     # Module B: Hash computation
â”‚   â”œâ”€â”€ opencv_compare.py                    # Module C: OpenCV comparison
â”‚   â”œâ”€â”€ auto_reverse_search.py               # Module D: Selenium automation
â”‚   â””â”€â”€ plagiarism_engine.py                 # Module F: Master pipeline
â”‚
â”œâ”€â”€ queue/
â”‚   â””â”€â”€ diagramQueue.ts                      # Module E: Queue definition
â”‚
â”œâ”€â”€ workers/
â”‚   â””â”€â”€ diagramWorker.ts                     # Module E: Background worker
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ diagram_hashes.db                     # SQLite database (auto-created)
â”‚   â””â”€â”€ results/                             # Job results (auto-created)
â”‚       â””â”€â”€ <jobId>.json
â”‚
â”œâ”€â”€ public/
â”‚   â””â”€â”€ diagrams/
â”‚       â”œâ”€â”€ extracted/                       # Extracted diagrams
â”‚       â”‚   â””â”€â”€ <pdfName>/
â”‚       â”‚       â””â”€â”€ <page>-<index>.png
â”‚       â””â”€â”€ reference/                       # Reference diagrams
â”‚
â””â”€â”€ uploads/                                 # Uploaded PDFs
```

## ğŸ”„ End-to-End Pipeline Flow

### 1. User Uploads PDF
```
User â†’ /forensics â†’ Upload PDF â†’ POST /api/forensics/scan
```

### 2. Job Queued
```
API â†’ diagramQueue.add() â†’ Redis â†’ Job stored
```

### 3. Worker Processes Job
```
Worker â†’ Reads job from queue â†’ Calls plagiarism_engine.py
```

### 4. Plagiarism Engine Pipeline

```
plagiarism_engine.py:
  â”‚
  â”œâ”€â†’ Step 1: Extract Diagrams
  â”‚   â””â”€â†’ pdf_extractor.py
  â”‚       â”œâ”€â†’ Extract embedded images (PyMuPDF)
  â”‚       â”œâ”€â†’ Render vector graphics
  â”‚       â””â”€â†’ Save to public/diagrams/extracted/<pdfName>/
  â”‚
  â”œâ”€â†’ Step 2: For Each Diagram
  â”‚   â”‚
  â”‚   â”œâ”€â†’ 2a. Compute Hashes
  â”‚   â”‚   â””â”€â†’ image_hashing.py
  â”‚   â”‚       â”œâ”€â†’ Generate pHash, dHash, aHash
  â”‚   â”‚       â””â”€â†’ Store in SQLite (data/diagram_hashes.db)
  â”‚   â”‚
  â”‚   â”œâ”€â†’ 2b. Local Comparison
  â”‚   â”‚   â””â”€â†’ opencv_compare.py
  â”‚   â”‚       â”œâ”€â†’ ORB feature detection
  â”‚   â”‚       â”œâ”€â†’ SSIM computation
  â”‚   â”‚       â””â”€â†’ Compare with reference/ directory
  â”‚   â”‚
  â”‚   â””â”€â†’ 2c. Reverse Image Search
  â”‚       â””â”€â†’ auto_reverse_search.py
  â”‚           â”œâ”€â†’ Selenium automation
  â”‚           â”œâ”€â†’ Upload to Google Images
  â”‚           â””â”€â†’ Extract results
  â”‚
  â””â”€â†’ Step 3: Generate Report
      â”œâ”€â†’ Combine all results
      â”œâ”€â†’ Make plagiarism decision
      â””â”€â†’ Save to data/results/<jobId>.json
```

### 5. Frontend Polls for Results
```
Frontend â†’ GET /api/forensics/status?jobId=... (every 2s)
         â†’ GET /api/forensics/report?jobId=... (when complete)
         â†’ Display report
```

## ğŸ” Detection Algorithms

### Hash-Based Detection

**Perceptual Hash (pHash):**
- Detects visually similar images
- Hash distance < 10 â†’ Strong duplicate indicator
- Stored in SQLite for fast lookup

**Difference Hash (dHash):**
- Detects horizontal gradients
- Complementary to pHash

**Average Hash (aHash):**
- Simple average-based hash
- Fast but less accurate

### OpenCV Feature Matching

**ORB (Oriented FAST and Rotated BRIEF):**
- Detects keypoints and descriptors
- Match ratio > 35% â†’ Likely copied
- Handles rotation and scaling

**SSIM (Structural Similarity Index):**
- Measures structural similarity
- Score > 0.65 â†’ Likely copied
- Score > 0.75 â†’ High confidence

### Reverse Image Search

**Google Images:**
- Uploads image via Selenium
- Extracts similar images
- Finds matching web pages

**Bing Visual Search:**
- Alternative search engine
- Cross-validation

## ğŸ“Š Decision Logic

### Plagiarism Decision Rules

```python
confidence = 0.0

# Hash match (strong indicator)
if hash_similarity > 0.9:
    confidence += 0.3

# OpenCV SSIM (high confidence)
if ssim > 0.75:
    confidence += 0.4

# ORB matches
if orb_matches > 0.35:
    confidence += 0.2

# Reverse search results
if google_found_similar_images:
    confidence += 0.3

# Final decision
if confidence >= 0.7:
    decision = "heavily plagiarized"
elif confidence >= 0.4:
    decision = "partially plagiarized"
else:
    decision = "original"
```

## ğŸ› ï¸ Module Details

### Module A: PDF Extraction

**File:** `scripts/pdf_extractor.py`

**Functions:**
- `extract_diagrams(pdf_path, output_base_dir) -> List[str]`

**Methods:**
1. Extract embedded images (PyMuPDF)
2. Render vector graphics (page rendering)
3. Filter small images (< 150px)

**Output:**
- PNG files in `public/diagrams/extracted/<pdfName>/<page>-<index>.png`

### Module B: Image Hashing

**File:** `scripts/image_hashing.py`

**Database Schema:**
```sql
CREATE TABLE diagram_hashes (
    id INTEGER PRIMARY KEY,
    filePath TEXT UNIQUE,
    pHash TEXT,
    dHash TEXT,
    aHash TEXT,
    createdAt DATETIME
);
```

**Functions:**
- `compute_hashes(image_path) -> Dict`
- `store_hashes(image_path, hashes) -> bool`
- `compare_hashes(hash1, hash2) -> float`
- `find_similar(image_path, threshold) -> List[Dict]`

### Module C: OpenCV Comparison

**File:** `scripts/opencv_compare.py`

**Functions:**
- `compare_images(image1, image2) -> Dict`
- `is_likely_copied(image1, image2) -> Dict`
- `compare_with_directory(query_image, ref_dir) -> Dict`

**Thresholds:**
- ORB matches > 35% â†’ Likely copied
- SSIM > 0.65 â†’ Likely copied

### Module D: Reverse Search

**File:** `scripts/auto_reverse_search.py`

**Functions:**
- `search_google(image_path) -> Dict`
- `search_bing(image_path) -> Dict`

**Features:**
- Headless/visible mode
- Anti-detection (UA spoofing, throttling)
- Error handling

### Module E: Queue System

**Files:**
- `queue/diagramQueue.ts` - Queue definition
- `workers/diagramWorker.ts` - Worker process

**Job Types:**
- `extract` - PDF extraction
- `hash` - Hash computation
- `compare` - OpenCV comparison
- `reverse-search` - Reverse image search
- `plagiarism` - Full pipeline

### Module F: Master Pipeline

**File:** `scripts/plagiarism_engine.py`

**Pipeline:**
1. Extract diagrams
2. For each diagram:
   - Compute hashes
   - Compare locally
   - Reverse search
3. Generate report

### Module G: Frontend UI

**File:** `app/forensics/page.tsx`

**Features:**
- PDF upload
- Progress tracking
- Report display
- Diagram previews
- Similarity charts

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
# Python
pip install -r python-service/requirements-forensics.txt

# Node.js
npm install
```

### 2. Start Services

```bash
# Terminal 1: Redis
redis-server

# Terminal 2: Worker
npm run worker

# Terminal 3: Next.js
npm run dev
```

### 3. Access UI

Navigate to: `http://localhost:3000/forensics`

## ğŸ“ Sample Report Structure

```json
{
  "jobId": "plagiarism_1234567890_abc123",
  "pdfPath": "uploads/1234567890_document.pdf",
  "totalDiagrams": 5,
  "diagrams": [
    {
      "diagram": "diagrams/extracted/document/page_1-1.png",
      "index": 1,
      "localSimilarity": {
        "bestMatch": {
          "image": "reference/similar.png",
          "score": 85.5,
          "ssim": 0.78
        }
      },
      "reverseImageSearch": {
        "bestGuess": "Flowchart diagram",
        "similarImagesCount": 12,
        "matchingPagesCount": 5
      },
      "hashMatches": {
        "count": 2,
        "highestSimilarity": 0.95
      },
      "decision": "heavily plagiarized",
      "confidence": 0.85,
      "indicators": [
        "High SSIM similarity: 0.78",
        "ORB match percentage: 85.50%",
        "Visually similar images found on Google"
      ]
    }
  ],
  "summary": {
    "total": 5,
    "original": 2,
    "partiallyPlagiarized": 1,
    "heavilyPlagiarized": 2,
    "averageConfidence": 0.52,
    "riskLevel": "high"
  }
}
```

## ğŸ”§ Configuration Options

### Python Scripts

**pdf_extractor.py:**
- Minimum image size: 150px (configurable)
- Output format: PNG
- Vector rendering: 2x resolution

**image_hashing.py:**
- Hash size: 16 (configurable)
- Similarity threshold: 0.8 (configurable)

**opencv_compare.py:**
- ORB features: 1000 (configurable)
- ORB threshold: 0.35 (configurable)
- SSIM threshold: 0.65 (configurable)

**auto_reverse_search.py:**
- Throttle delay: 1-2 seconds
- Upload wait: 5-8 seconds
- Headless mode: true (default)

### Queue Configuration

**diagramQueue.ts:**
- Max retries: 3
- Backoff: Exponential (2s)
- Concurrency: 2 jobs

## ğŸ› Common Issues

### Issue: Worker Not Starting

**Solution:**
- Check Redis is running
- Verify Python is in PATH
- Check worker logs

### Issue: Selenium Timeout

**Solution:**
- Update ChromeDriver
- Check Chrome version compatibility
- Increase wait times

### Issue: OpenCV Import Error

**Solution:**
```bash
pip install opencv-python scikit-image
```

### Issue: Jobs Stuck

**Solution:**
- Restart worker
- Clear Redis queue
- Check Python script errors

## ğŸ“ˆ Performance Optimization

1. **Parallel Processing:** Worker processes 2 jobs concurrently
2. **Caching:** Hashes stored in SQLite for fast lookup
3. **Throttling:** Reverse search throttled to avoid detection
4. **Batch Operations:** Multiple diagrams processed in sequence

## ğŸ”’ Security Notes

- All processing is local
- No external API calls (except reverse search)
- Uploaded files stored securely
- SQLite database not publicly accessible
- Consider authentication for production

## ğŸ“š Additional Resources

- **PyMuPDF Docs:** https://pymupdf.readthedocs.io/
- **OpenCV Docs:** https://docs.opencv.org/
- **Selenium Docs:** https://www.selenium.dev/documentation/
- **BullMQ Docs:** https://docs.bullmq.io/

## âœ… Testing Checklist

- [ ] Redis running
- [ ] Worker process running
- [ ] Python dependencies installed
- [ ] ChromeDriver installed
- [ ] Test PDF uploads successfully
- [ ] Diagrams extracted correctly
- [ ] Hashes computed and stored
- [ ] OpenCV comparison works
- [ ] Reverse search completes
- [ ] Report generated correctly
- [ ] Frontend displays results

## ğŸ‰ Success!

Your Diagram Forensics Engine is now complete and ready to detect diagram plagiarism!

